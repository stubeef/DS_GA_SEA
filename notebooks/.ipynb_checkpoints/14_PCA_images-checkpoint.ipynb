{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis applied to images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on Shankar Muthuswamy's example at https://shankarmsy.github.io/posts/pca-sklearn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before using PCA, let us try and understand as well as display the original images.\n",
    "#Note the Olivetti faces data is available in scikit-learn but not locally. It needs to be downloaded.\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "oliv=fetch_olivetti_faces()\n",
    "#print oliv.keys()\n",
    "print oliv.data.shape \n",
    "#tells us there are 400 images that are 64 x 64 (4096) pixels each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oliv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup a figure 6 inches by 6 inches\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the faces, each image is 64 by 64 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(oliv.images[i], cmap=plt.cm.bone, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see how much of the variance is retained if we compressed these down to a 8x8 (64) pixel images.\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "X,y=oliv.data, oliv.target\n",
    "pca_oliv = PCA(n_components=64)\n",
    "X_proj = pca_oliv.fit_transform(X)\n",
    "print X_proj.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.cumsum(pca_oliv.explained_variance_ratio_.sum())\n",
    "#That's terrific, compressing a 64x64 pixel image down to an 8x8 image\n",
    "#still retains about 89.7% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is great so far. Now we have a reduced 64x64 dimension(4096 feature)dataset, generated with 64 principal components.\n",
    "# Each of these principal components can explain some variation in the original dataset.\n",
    "# The parameter components_ of the #estimator object gives the components with maximum variance\n",
    "\n",
    "# Below we'll try to visualize the top 8 principal components. \n",
    "# This is NOT a reconstruction of the original data, just \n",
    "# visualizing the principal components as images.\n",
    "# The principal components are vectors of the length = to the number of # features 4096.\n",
    "# We'll need to reshape it to a 64 x 64 matrix.\n",
    "\n",
    "# Setup a figure 8 inches by 8 inches\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the faces, each image is 64 by 64 pixels\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(5, 5, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.reshape(pca_oliv.components_[i,:], (64,64)), cmap=plt.cm.bone, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awesome, let's now try to reconstruct the images using the new reduced dataset.\n",
    "# In other words, we transformed the\n",
    "# 64x64 pixel images into 8x8 images. Now to visualize how these images look we need to inverse transform\n",
    "# the 8x8 images back to 64x64 dimension.\n",
    "# Note that we're not reverting back to the original data, we're simply going back to the\n",
    "# actual dimension of the original images so we can visualize them.\n",
    "\n",
    "X_inv_proj = pca_oliv.inverse_transform(X_proj)\n",
    "#reshaping as 400 images of 64x64 dimension\n",
    "X_proj_img = np.reshape(X_inv_proj,(400,64,64))\n",
    "\n",
    "#Setup a figure 8 inches by 8 inches\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the faces, each image is 64 by 64 dimension but 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_proj_img[i], cmap=plt.cm.bone, interpolation='nearest')\n",
    "\n",
    "# This is not bad at all, the image still looks pretty good but the finer details are missing,\n",
    "# which is okay considering we've reduced dimensionality (and image file size) by 64 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized PCA algorithm\n",
    "Let's try an alternative dimensionality reduction scikit learn PCA function.  The Randomized PCA function is a variant of PCA that often is good to break down/compress original data/images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA\n",
    "rpca_oliv = PCA(64,svd_solver='randomized').fit(X)\n",
    "print \"Randomized PCA with 64 components: \", np.sum(rpca_oliv.explained_variance_ratio_)\n",
    "print \"PCA with 64 components: \", np.sum(pca_oliv.explained_variance_ratio_)\n",
    "\n",
    "#The cumulative explained variance doesn't tell us much. It actually is slightly less than PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and plot the principal components to see if the images look any better.\n",
    "\n",
    "# Setup a figure 8 inches by 8 inches\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the faces, each image is 64 by 64 pixels\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(5, 5, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.reshape(rpca_oliv.components_[i,:], (64,64)),cmap=plt.cm.bone, interpolation='nearest')\n",
    "\n",
    "# Interesting! Some of the images actually look a bit better than those rendered with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now try to reconstruct the images back into 64x64 inges from using the new reduced dataset.\n",
    "# Note that we're not reverting back to the original data, we're simply going back to the\n",
    "# actual dimension of the original images so we can visualize them.\n",
    "\n",
    "X_inv_proj = rpca_oliv.inverse_transform(X_proj)\n",
    "#reshaping as 400 images of 64x64 dimension\n",
    "X_proj_img = np.reshape(X_inv_proj,(400,64,64))\n",
    "\n",
    "#Setup a figure 8 inches by 8 inches\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the faces, each image is 64 by 64 dimension but 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_proj_img[i], cmap=plt.cm.bone, interpolation='nearest')\n",
    "\n",
    "# This is not bad at all, the image still looks pretty good but the finer details are missing,\n",
    "# which is okay considering we've reduced dimensionality (and image file size) by 64 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different.  But are they better images in this case than straight PCA.  You be the judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Okay, let's import this image called \"colorful_bird.png\", stored in the same working directory as this notebook. import matplotlib.image as mpimg\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('images/colorful_bird_.png')\n",
    "\n",
    "#Now, let's look at the size of this numpy array object img as well as plot it using imshow.\n",
    "print img.shape\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the shape above we see that the array is a 3 dimentional array with 425 rows, 283 columns and three values deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reshape it into a format that PCA can understand.\n",
    "# 849 = 283 * 3\n",
    "img_r = np.reshape(img, (425, 849))\n",
    "print img_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets run RandomizedPCA with 64 components and transform the image\n",
    "ipca = PCA(64, svd_solver='randomized').fit(img_r)\n",
    "img_c = ipca.transform(img_r)\n",
    "print img_c.shape\n",
    "print np.sum(ipca.explained_variance_ratio_)\n",
    "#Great, looks like with 64 components we can explain about 98% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize how PCA has performed this compression, let's inverse transform the PCA output and \n",
    "# reshape for visualization using imshow.\n",
    "temp = ipca.inverse_transform(img_c)\n",
    "print temp.shape\n",
    "\n",
    "# reshaping 849 back to the original 253 * 3\n",
    "temp = np.reshape(temp, (425,283,3))\n",
    "\n",
    "print temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets visualize like before with imshow and see how our image looks reduced to just 64 components then inversed back to a 768 pixel x 1024 pixel image\n",
    "plt.axis('off')\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of that image look pretty good considering the drastic reduction in dimensions we did.  Some areas do not look good at all.  We would need to explore some of the other dimensionality reduction methods in scikit learn to see if we can do better with this level of dimensionality reduction of color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets run regular PCA with 64 components (8x8 pixels) and transform the image to see if that works better\n",
    "ipca = PCA(64).fit(img_r)\n",
    "img_c = ipca.transform(img_r)\n",
    "print img_c.shape\n",
    "print np.sum(ipca.explained_variance_ratio_)\n",
    "# Great, looks like with 64 components we can explain about 99% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets inverse back to a 425x283 image and see how that looks\n",
    "# To visualize how PCA has performed this compression, let's inverse transform the PCA output and \n",
    "# reshape for visualization using imshow.\n",
    "temp = ipca.inverse_transform(img_c)\n",
    "print temp.shape\n",
    "\n",
    "# reshaping 849 back to the original 253 * 3\n",
    "temp = np.reshape(temp, (425,283,3))\n",
    "\n",
    "print temp.shape\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much better so we would have to try other dimensionality reduction techniques on color images to see if we can do better.  But for certain purposes such as image recognition the reduction results we have might be good enough.  Try some other images and note that the areas that are poorly colored are usually in areas where the colors are slowly changing from pixel to pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
