{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis applied to the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# increase default figure and font sizes for easier viewing\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['sepal_length','sepal_width','petal_length','petal_width', 'species']\n",
    "iris = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create X\n",
    "feature_cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "X = iris[feature_cols]\n",
    "target_names = iris.species\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all features and response need to be numbers for scikit-learn\n",
    "# map each iris species to a number\n",
    "iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "y = iris.species_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's reduce it to three components\n",
    "from sklearn import decomposition\n",
    "pca3 = decomposition.PCA(n_components=3)\n",
    "X_trf_3 = pca3.fit_transform(X)\n",
    "print(X_trf_3[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca3.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca3.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's reduce it to two components\n",
    "pca2 = decomposition.PCA(n_components=2)\n",
    "X_trf_2 = pca2.fit_transform(X)\n",
    "pca2.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's reduce it to one components\n",
    "pca1 = decomposition.PCA(n_components=1)\n",
    "X_trf_1 = pca1.fit_transform(X)\n",
    "pca1.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All components (same as the original features)\n",
    "pca_all = decomposition.PCA() # alternate way to use all 4 components: decomposition.PCA(n_components=4)\n",
    "X_trf_all = pca_all.fit_transform(X)\n",
    "pca_all.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Choosing components\n",
    "pca4 = decomposition.PCA(n_components=4)\n",
    "X_trf = pca4.fit_transform(X)\n",
    "\n",
    "print 'explained variance ratio (all 4 components): ', pca4.explained_variance_ratio_\n",
    "print 'sum of explained variance ratio (all 4 components): ', pca4.explained_variance_ratio_.sum()\n",
    "plt.cla()\n",
    "plt.plot(pca4.explained_variance_ratio_)\n",
    "plt.title('Variance explained by each principal component\\n')\n",
    "plt.ylabel(' % Variance Explained')\n",
    "plt.xlabel('Principal component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "log_reg = logistic.fit(X,y)\n",
    "scores = cross_val_score(log_reg, X, y, cv=10, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe_trf_3 = Pipeline([('pca_3', decomposition.PCA(n_components=3)),\n",
    "                 ('logistic', LogisticRegression())])\n",
    "scores_trf_3 = cross_val_score(pipe_trf_3, X, y, cv=10, scoring='accuracy')\n",
    "scores_trf_3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_trf_2 = Pipeline([('pca_2', decomposition.PCA(n_components=2)),\n",
    "                 ('logistic', LogisticRegression())])\n",
    "scores_trf_2 = cross_val_score(pipe_trf_2, X, y, cv=10, scoring='accuracy')\n",
    "scores_trf_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fits PCA, transforms data, fits the Logistic Regression mode with one component, and scores accuracy\n",
    "# on the transformed data\n",
    "pipe_trf_1 = Pipeline([('pca_1', decomposition.PCA(n_components=1)),\n",
    "                 ('logistic', LogisticRegression())])\n",
    "scores_trf_1 = cross_val_score(pipe_trf_1, X, y, cv=10, scoring='accuracy')\n",
    "scores_trf_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_trf_2 = Pipeline([('pca_2', decomposition.PCA(n_components=2)),\n",
    "                 ('logistic', LogisticRegression())])\n",
    "scores_trf_2 = cross_val_score(pipe_trf_2, X, y, cv=10, scoring='accuracy')\n",
    "scores_trf_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn it back into its 4 components using only 2 principal components\n",
    "X_reconstituted2 = pca2.inverse_transform(X_trf_2)\n",
    "scores_trf_recon2 = cross_val_score(log_reg, X_reconstituted2, y, cv=10, scoring='accuracy')\n",
    "scores_trf_recon2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn it back into its 4 components using only 1 principal components\n",
    "X_reconstituted1 = pca1.inverse_transform(X_trf_1)\n",
    "scores_trf_recon1 = cross_val_score(log_reg, X_reconstituted1, y, cv=10, scoring='accuracy')\n",
    "scores_trf_recon1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn it back into its 4 components using only 3 principal components\n",
    "X_reconstituted3 = pca3.inverse_transform(X_trf_3)\n",
    "scores_trf_recon3 = cross_val_score(log_reg, X_reconstituted3, y, cv=10, scoring='accuracy')\n",
    "scores_trf_recon3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn it back into its 4 components using 4 principal components\n",
    "pca4 = decomposition.PCA(n_components=4)\n",
    "X_trf_4 = pca4.fit_transform(X)\n",
    "pca4.explained_variance_ratio_.sum()\n",
    "X_reconstituted4 = pca4.inverse_transform(X_trf_4)\n",
    "scores_trf_recon4 = cross_val_score(log_reg, X_reconstituted4, y, cv=10, scoring='accuracy')\n",
    "scores_trf_recon4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_reconstituted1[0]\n",
    "print X_reconstituted2[0]\n",
    "print X_reconstituted3[0]\n",
    "print X_reconstituted4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
